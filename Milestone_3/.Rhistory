# Shuffle the dataset
shuffled_data <- subset_normalized[random_indices, ]
# Split the shuffled dataset into training and testing sets
train_data <- shuffled_data[1:round(train_proportion * nrow(shuffled_data)), ]
test_data <- shuffled_data[(round(train_proportion * nrow(shuffled_data)) + 1):nrow(shuffled_data), ]
# Define neural network model for 1 hidden layer
nn_model_1 <- neuralnet(
formula = t_cap ~ t_hh + t_rd + t_rsa + t_ttlh,
data = train_data,
hidden = 1,  # One hidden layer
)
plot(nn_model_1)
nn_model_1 <- neuralnet(
formula = t_cap ~ t_hh + t_rd + t_rsa + t_ttlh,
data = train_data,
hidden = 1,  # One hidden layer
stepmax = 1e6  # Increase maximum number of steps
)
predictions_1 <- predict(nn_model_1, as.matrix(test_data[, c("t_hh", "t_rd", "t_rsa", "t_ttlh")]))
correlation_1 <- cor(predictions_1, test_data$t_cap)
mse_1 <- mean((predictions_1 - test_data$t_cap)^2)
# Calculate Mean Squared Error (MSE)
mse_1 <- mean((predictions_1 - test_data$t_cap)^2)
# Calculate Root Mean Squared Error (RMSE)
rmse_1 <- sqrt(mse_1)
# Calculate Mean Absolute Error (MAE)
mae_1 <- mean(abs(predictions_1 - test_data$t_cap))
# Check if weights were calculated
if (!is.null(nn_model_1$weights)) {
# Visualize Network Topology and save plot as file
png("neuralnet_plot_hidden_1.png")
plot(nn_model_1)
dev.off()
}
cat("Number of Hidden Layers: 1\n")
cat("Mean Squared Error (MSE):", mse_1, "\n")
cat("Root Mean Squared Error (RMSE):", rmse_1, "\n")
cat("Mean Absolute Error (MAE):", mae_1, "\n")
cat("Correlation:", correlation_1, "\n\n")
print  print("Number of Hidden Layers: 1\n")
print("Number of Hidden Layers: 1\n")
print("Number of Hidden Layers: 1")
cat("Number of Hidden Layers: 1")
mse_1
rmse_1 <- sqrt(mse_1)
print(mse_1)
if (!is.null(nn_model_1$weights)) {
# Visualize Network Topology and save plot as file
png("neuralnet_plot_hidden_1.png")
plot(nn_model_1)
dev.off()
}
print(nn_model_1)
View(nn_model_1)
predictions_1 <- predict(nn_model_1, as.matrix(test_data[, c("t_hh", "t_rd", "t_rsa", "t_ttlh")]))
print(predictions_1)
clear
clena
clean
# Load required libraries
library(neuralnet)
library(dplyr)
# Import dataset
dataset <- read.csv("datasets/cleaned_dataset.csv")
# Subset the dataset
subset <- dataset[, c("t_cap", "t_hh", "t_rd", "t_rsa", "t_ttlh")]
subset <- na.omit(subset)
# Normalize input variables to [0-1] range
normalize <- function(x) {
(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}
subset_normalized <- subset %>% mutate(across(where(is.numeric), normalize))
subset_normalized <- subset_normalized %>%
sample_frac(size = 0.2, replace = FALSE)
# Define proportion for training data
train_proportion <- 0.7
# Generate random indices to shuffle the dataset
set.seed(123)  # for reproducibility
random_indices <- sample(nrow(subset_normalized))
# Shuffle the dataset
shuffled_data <- subset_normalized[random_indices, ]
# Split the shuffled dataset into training and testing sets
train_data <- shuffled_data[1:round(train_proportion * nrow(shuffled_data)), ]
test_data <- shuffled_data[(round(train_proportion * nrow(shuffled_data)) + 1):nrow(shuffled_data), ]
# Define neural network model for 1 hidden layer
nn_model_1 <- neuralnet(
formula = t_cap ~ t_hh + t_rd + t_rsa + t_ttlh,
data = train_data,
hidden = 1,  # One hidden layer
)
# Load required libraries
library(neuralnet)
library(dplyr)
# Import dataset
dataset <- read.csv("datasets/cleaned_dataset.csv")
# Subset the dataset
subset <- dataset[, c("t_cap", "t_hh", "t_rd", "t_rsa", "t_ttlh")]
subset <- na.omit(subset)
# Normalize input variables to [0-1] range
normalize <- function(x) {
(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}
subset_normalized <- subset %>% mutate(across(where(is.numeric), normalize))
sampled_data <- subset_normalized %>%
sample_frac(size = 0.2, replace = FALSE)
# Define proportion for training data
train_proportion <- 0.7
# Generate random indices to shuffle the dataset
set.seed(123)  # for reproducibility
random_indices <- sample(nrow(subset_normalized))
# Shuffle the dataset
shuffled_data <- subset_normalized[random_indices, ]
# Split the shuffled dataset into training and testing sets
train_data <- shuffled_data[1:round(train_proportion * nrow(shuffled_data)), ]
test_data <- shuffled_data[(round(train_proportion * nrow(shuffled_data)) + 1):nrow(shuffled_data), ]
# Define neural network model with adjusted parameters
nn_model <- neuralnet(
formula = t_cap ~ t_hh + t_rd + t_rsa + t_ttlh,
data = train_data
)
# Split the shuffled dataset into training and testing sets
train_data <- shuffled_data[1:round(train_proportion * nrow(shuffled_data)), ]
test_data <- shuffled_data[(round(train_proportion * nrow(shuffled_data)) + 1):nrow(shuffled_data), ]
# Define neural network model with adjusted parameters
nn_model <- neuralnet(
formula = t_cap ~ t_hh + t_rd + t_rsa + t_ttlh,
data = train_data
)
predictions <- compute(nn_model, test_data[2:5])
predictions <- preditct(nn_model, test_data[2:5])
predictions <- predict(nn_model, test_data[2:5])
predictions_1 <- predict(nn_model_1, as.matrix(test_data[, c("t_hh", "t_rd", "t_rsa", "t_ttlh")]))
predictions_1 <- predict(nn_model_1, as.matrix(test_data[2:5)])
predictions_1 <- predict(nn_model_1, as.matrix(test_data[2:5)]))
predictions_1 <- predict(nn_model_1, as.matrix(test_data[2:5]))
View(test_data)
# Load required libraries
library(neuralnet)
library(dplyr)
# Import dataset
dataset <- read.csv("datasets/cleaned_dataset.csv")
str(dataset)
# Subset the dataset
subset <- dataset[, c("t_cap", "t_hh", "t_rd", "t_rsa", "t_ttlh")]
subset <- na.omit(subset)
# Normalize input variables to [0-1] range
normalize <- function(x) {
(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}
subset_normalized <- as.data.frame(lapply(subset,normalize))
sampled_data <- subset_normalized %>%
sample_frac(size = 0.2, replace = FALSE)
# Load required libraries
library(neuralnet)
library(dplyr)
# Import dataset
dataset <- read.csv("datasets/cleaned_dataset.csv")
str(dataset)
# Subset the dataset
subset <- dataset[, c("t_cap", "t_hh", "t_rd", "t_rsa", "t_ttlh")]
subset <- na.omit(subset)
# Normalize input variables to [0-1] range
normalize <- function(x) {
(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}
subset_normalized <- as.data.frame(lapply(subset,normalize))
sampled_data <- subset_normalized %>%
sample_frac(size = 0.2, replace = FALSE)
# Define proportion for training data
train_proportion <- 0.7
# Generate random indices to shuffle the dataset
set.seed(123)  # for reproducibility
random_indices <- sample(nrow(sampled_data))
# Shuffle the dataset
shuffled_data <- sampled_data[random_indices, ]
# Split the shuffled dataset into training and testing sets
train_data <- shuffled_data[1:round(train_proportion * nrow(shuffled_data)), ]
test_data <- shuffled_data[(round(train_proportion * nrow(shuffled_data)) + 1):nrow(shuffled_data), ]
summary(train_data)
View(train_data)
# Load required libraries
library(neuralnet)
library(dplyr)
# Import dataset
dataset <- read.csv("datasets/cleaned_dataset.csv")
str(dataset)
# Subset the dataset
subset <- dataset[, c("t_cap", "t_hh", "t_rd", "t_rsa", "t_ttlh")]
subset <- na.omit(subset)
# Normalize input variables to [0-1] range
normalize <- function(x) {
(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}
subset_normalized <- as.data.frame(lapply(subset,normalize))
sampled_data <- subset_normalized %>%
sample_frac(size = 0.2, replace = FALSE)
# Define proportion for training data
train_proportion <- 0.7
# Generate random indices to shuffle the dataset
set.seed(123)  # for reproducibility
random_indices <- sample(nrow(sampled_data))
# Shuffle the dataset
shuffled_data <- sampled_data[random_indices, ]
# Split the shuffled dataset into training and testing sets
train_data <- shuffled_data[1:round(train_proportion * nrow(shuffled_data)), ]
test_data <- shuffled_data[(round(train_proportion * nrow(shuffled_data)) + 1):nrow(shuffled_data), ]
# Define neural network model with adjusted parameters
nn_model <- neuralnet(
formula = t_cap ~ t_hh + t_rd + t_rsa + t_ttlh,
data = train_data
)
plot(nnmodel_1)
plot(nnmodel)
plot(nn_model)
nn_model_5 <- neuralnet(
formula = t_cap ~ t_hh + t_rd + t_rsa + t_ttlh,
data = train_data,
hidden = 1,  # Five hidden layers
)
# Load required libraries
library(neuralnet)
library(dplyr)
# Import dataset
dataset <- read.csv("datasets/cleaned_dataset.csv")
# Subset the dataset
subset <- dataset[, c("t_cap", "t_hh", "t_rd", "t_rsa", "t_ttlh")]
subset <- na.omit(subset)
# Normalize input variables to [0-1] range
normalize <- function(x) {
(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}
subset_normalized <- subset %>% mutate(across(where(is.numeric), normalize))
subset_normalized <- subset_normalized %>%
sample_frac(size = 0.2, replace = FALSE)
# Define proportion for training data
train_proportion <- 0.7
# Generate random indices to shuffle the dataset
set.seed(123)  # for reproducibility
random_indices <- sample(nrow(subset_normalized))
# Shuffle the dataset
shuffled_data <- subset_normalized[random_indices, ]
# Split the shuffled dataset into training and testing sets
train_data <- shuffled_data[1:round(train_proportion * nrow(shuffled_data)), ]
test_data <- shuffled_data[(round(train_proportion * nrow(shuffled_data)) + 1):nrow(shuffled_data), ]
# Define the number of hidden layers to iterate over
hidden_layers <- c(1, 5, 10)
# Open a text file to save the results
sink("neuralnet_results.txt")
# Iterate over different numbers of hidden layers
for (hl in hidden_layers) {
cat("Number of Hidden Layers:", hl, "\n")
# Define neural network model
nn_model <- neuralnet(
formula = t_cap ~ t_hh + t_rd + t_rsa + t_ttlh,
data = train_data,
hidden = hl
)
# Check if weights were calculated
if (!is.null(nn_model$weights)) {
# Visualize Network Topology and save plot as file
plot_file <- paste0("neuralnet_plot_hidden_", hl, ".png")
png(plot_file)
plot(nn_model)
dev.off()
# Make predictions on testing data
predictions <- predict(nn_model, as.matrix(test_data[, c("t_hh", "t_rd", "t_rsa", "t_ttlh")]))
# Compute correlation between predicted and actual capacity
correlation <- cor(predictions, test_data$t_cap)
# Calculate Mean Squared Error (MSE)
mse <- mean((predictions - test_data$t_cap)^2)
# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mse)
# Calculate Mean Absolute Error (MAE)
mae <- mean(abs(predictions - test_data$t_cap))
# Print the metrics
cat("Mean Squared Error (MSE):", mse, "\n")
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
cat("Mean Absolute Error (MAE):", mae, "\n")
cat("Correlation:", correlation, "\n\n")
} else {
cat("Weights were not calculated for", hl, "hidden layers.\n\n")
}
}
# Load required libraries
library(neuralnet)
library(dplyr)
# Import dataset
dataset <- read.csv("datasets/cleaned_dataset.csv")
# Subset the dataset
subset <- dataset[, c("t_cap", "t_hh", "t_rd", "t_rsa", "t_ttlh")]
subset <- na.omit(subset)
# Normalize input variables to [0-1] range
normalize <- function(x) {
(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}
subset_normalized <- subset %>% mutate(across(where(is.numeric), normalize))
subset_normalized <- subset_normalized %>%
sample_frac(size = 0.2, replace = FALSE)
# Define proportion for training data
train_proportion <- 0.7
# Generate random indices to shuffle the dataset
set.seed(123)  # for reproducibility
random_indices <- sample(nrow(subset_normalized))
# Shuffle the dataset
shuffled_data <- subset_normalized[random_indices, ]
# Split the shuffled dataset into training and testing sets
train_data <- shuffled_data[1:round(train_proportion * nrow(shuffled_data)), ]
test_data <- shuffled_data[(round(train_proportion * nrow(shuffled_data)) + 1):nrow(shuffled_data), ]
# Define the number of hidden layers to iterate over
hidden_layers <- c(1, 5)
# Open a text file to save the results
sink("neuralnet_results.txt")
# Iterate over different numbers of hidden layers
for (hl in hidden_layers) {
cat("Number of Hidden Layers:", hl, "\n")
# Define neural network model
nn_model <- neuralnet(
formula = t_cap ~ t_hh + t_rd + t_rsa + t_ttlh,
data = train_data,
hidden = hl
)
# Check if weights were calculated
if (!is.null(nn_model$weights)) {
# Visualize Network Topology and save plot as file
plot_file <- paste0("neuralnet_plot_hidden_", hl, ".png")
png(plot_file)
plot(nn_model)
dev.off()
# Make predictions on testing data
predictions <- predict(nn_model, as.matrix(test_data[, c("t_hh", "t_rd", "t_rsa", "t_ttlh")]))
# Compute correlation between predicted and actual capacity
correlation <- cor(predictions, test_data$t_cap)
# Calculate Mean Squared Error (MSE)
mse <- mean((predictions - test_data$t_cap)^2)
# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mse)
# Calculate Mean Absolute Error (MAE)
mae <- mean(abs(predictions - test_data$t_cap))
# Print the metrics
cat("Mean Squared Error (MSE):", mse, "\n")
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
cat("Mean Absolute Error (MAE):", mae, "\n")
cat("Correlation:", correlation, "\n\n")
} else {
cat("Weights were not calculated for", hl, "hidden layers.\n\n")
}
}
# Close the text file
sink()
# Load required libraries
library(neuralnet)
library(dplyr)
# Import dataset
dataset <- read.csv("datasets/cleaned_dataset.csv")
# Subset the dataset
subset <- dataset[, c("t_cap", "t_hh", "t_rd", "t_rsa", "t_ttlh")]
subset <- na.omit(subset)
# Normalize input variables to [0-1] range
normalize <- function(x) {
(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}
subset_normalized <- subset %>% mutate(across(where(is.numeric), normalize))
subset_normalized <- subset_normalized %>%
sample_frac(size = 0.2, replace = FALSE)
# Define proportion for training data
train_proportion <- 0.7
# Generate random indices to shuffle the dataset
set.seed(123)  # for reproducibility
random_indices <- sample(nrow(subset_normalized))
# Shuffle the dataset
shuffled_data <- subset_normalized[random_indices, ]
# Split the shuffled dataset into training and testing sets
train_data <- shuffled_data[1:round(train_proportion * nrow(shuffled_data)), ]
test_data <- shuffled_data[(round(train_proportion * nrow(shuffled_data)) + 1):nrow(shuffled_data), ]
# Define the number of hidden layers to iterate over
hidden_layers <- c(1, 5, 10)
# Open a text file to save the results
sink("neuralnet_results.txt")
# Iterate over different numbers of hidden layers
for (hl in hidden_layers) {
cat("Number of Hidden Layers:", hl, "\n")
# Define neural network model
nn_model <- neuralnet(
formula = t_cap ~ t_hh + t_rd + t_rsa + t_ttlh,
data = train_data,
hidden = hl,
stepmax = 1e6
)
# Check if weights were calculated
if (!is.null(nn_model$weights)) {
# Visualize Network Topology and save plot as file
plot_file <- paste0("generated_graphs/neuralnet_plot_hidden_", hl, ".png")
png(plot_file)
plot(nn_model)
dev.off()
# Make predictions on testing data
predictions <- predict(nn_model, as.matrix(test_data[, c("t_hh", "t_rd", "t_rsa", "t_ttlh")]))
# Compute correlation between predicted and actual capacity
correlation <- cor(predictions, test_data$t_cap)
# Calculate Mean Squared Error (MSE)
mse <- mean((predictions - test_data$t_cap)^2)
# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mse)
# Calculate Mean Absolute Error (MAE)
mae <- mean(abs(predictions - test_data$t_cap))
# Print the metrics
cat("Mean Squared Error (MSE):", mse, "\n")
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
cat("Mean Absolute Error (MAE):", mae, "\n")
cat("Correlation:", correlation, "\n\n")
} else {
cat("Weights were not calculated for", hl, "hidden layers.\n\n")
}
}
# Close the text file
sink()
plot(nn_model$weights)
plot(nn_model)
view(nn_model$weights)
Wiew(nn_model$weights)
View(nn_model$weights)
print(nn_model$weights)
predictions <- predict(nn_model, as.matrix(test_data[, c("t_hh", "t_rd", "t_rsa", "t_ttlh")]))
print(predictions$net.result)
predictions$net.result
View(predictions)
nn_model <- neuralnet(
formula = t_cap ~ t_hh + t_rd + t_rsa + t_ttlh,
data = train_data,
hidden =5,
stepmax = 1e6
)
nn_model <- neuralnet(
formula = t_cap ~ t_hh + t_rd + t_rsa + t_ttlh,
data = train_data,
hidden = 5,
stepmax = 1e6
)
png(filename = paste0("generated_graphs/neuralnet_plot_hidden_5.png"), width = 800, height = 600)
plot(nn_model)
nn_model <- neuralnet(
formula = t_cap ~ t_hh + t_rd + t_rsa + t_ttlh,
data = train_data,
hidden = 10,
stepmax = 1e6
)
plot(nn_model)
plot(nn_model)
# Load required libraries
library(neuralnet)
library(dplyr)
# Import dataset
dataset <- read.csv("datasets/cleaned_dataset.csv")
# Subset the dataset
subset <- dataset[, c("t_cap", "t_hh", "t_rd", "t_rsa", "t_ttlh")]
subset <- na.omit(subset)
# Normalize input variables to [0-1] range
normalize <- function(x) {
(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}
subset_normalized <- subset %>% mutate(across(where(is.numeric), normalize))
subset_normalized <- subset_normalized %>%
sample_frac(size = 0.2, replace = FALSE)
# Define proportion for training data
train_proportion <- 0.7
# Generate random indices to shuffle the dataset
set.seed(123)  # for reproducibility
random_indices <- sample(nrow(subset_normalized))
# Shuffle the dataset
shuffled_data <- subset_normalized[random_indices, ]
# Split the shuffled dataset into training and testing sets
train_data <- shuffled_data[1:round(train_proportion * nrow(shuffled_data)), ]
test_data <- shuffled_data[(round(train_proportion * nrow(shuffled_data)) + 1):nrow(shuffled_data), ]
# Define the number of hidden layers to iterate over
hidden_layers <- c(1, 5, 10)
# Open a text file to save the results
sink("generated_results/neuralnet_results.txt")
# Iterate over different numbers of hidden layers
for (hl in hidden_layers) {
cat("Number of Hidden Layers:", hl, "\n")
# Define neural network model
nn_model <- neuralnet(
formula = t_cap ~ t_hh + t_rd + t_rsa + t_ttlh,
data = train_data,
hidden = hl,
stepmax = 1e6
)
# Check if weights were calculated
if (!is.null(nn_model$weights)) {
# Visualize Network Topology and save plot as file
png(filename = paste0("generated_graphs/neuralnet_plot_hidden_", hl, ".png"), width = 800, height = 600)
plot(nn_model)
dev.off()
# Make predictions on testing data
predictions <- predict(nn_model, as.matrix(test_data[, c("t_hh", "t_rd", "t_rsa", "t_ttlh")]))
# Compute correlation between predicted and actual capacity
correlation <- cor(predictions, test_data$t_cap)
# Calculate Mean Squared Error (MSE)
mse <- mean((predictions - test_data$t_cap)^2)
# Calculate Root Mean Squared Error (RMSE)
rmse <- sqrt(mse)
# Calculate Mean Absolute Error (MAE)
mae <- mean(abs(predictions - test_data$t_cap))
# Print the metrics
cat("Mean Squared Error (MSE):", mse, "\n")
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
cat("Mean Absolute Error (MAE):", mae, "\n")
cat("Correlation:", correlation, "\n\n")
} else {
cat("Weights were not calculated for", hl, "hidden layers.\n\n")
}
}
